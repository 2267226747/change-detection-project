---
# Change Detection Project with InternViT & RL

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## ğŸ“– é¡¹ç›®æ¦‚è¿° (Project Overview)

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªé«˜ç²¾åº¦çš„å¤šæ ‡ç­¾å˜åŒ–æ£€æµ‹æ¡†æ¶ï¼Œä¸“ä¸ºå¤„ç†å¤æ‚çš„è¡—æ™¯å½±åƒï¼ˆSVIï¼‰å˜åŒ–æ£€æµ‹ä»»åŠ¡è€Œè®¾è®¡ã€‚ç³»ç»Ÿé‡‡ç”¨â€œSensing-Reasoningâ€äº¤æ›¿çš„ Transformer æ¶æ„ï¼Œç»“åˆå¼ºå¤§çš„ InternViT è§†è§‰ç¼–ç å™¨ï¼Œå®ç°å¯¹åŒæ—¶ç›¸å›¾åƒçš„æ·±åº¦ç‰¹å¾èåˆä¸ç†è§£ã€‚

æ­¤å¤–ï¼Œé¡¹ç›®å¼•å…¥äº† **å¼ºåŒ–å­¦ä¹  (PPO ç®—æ³•)** æ¨¡å—ï¼Œç”¨äºåœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¾®è°ƒç­–ç•¥ï¼Œä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼ˆå¦‚åŠ¨æ€ Query ä¿®æ­£ä¸æ¨ç†ç»ˆæ­¢å†³ç­–ï¼‰ã€‚

### æ ¸å¿ƒç‰¹æ€§
* **å¤šä»»åŠ¡å­¦ä¹  (Multitask Learning)**: åŒæ—¶å¤„ç† Road, Building, Greenery, Infrastructure å››å¤§ç±»å…± 31 ä¸ªå­ä»»åŠ¡çš„å˜åŒ–æ£€æµ‹.
* **Sensing-Reasoning æ¶æ„**: ç‹¬ç‰¹çš„ Transformer ç»“æ„ï¼Œäº¤æ›¿è¿›è¡Œè§†è§‰æ„ŸçŸ¥ (Sensing, Cross-Attn) ä¸ é€»è¾‘æ¨ç† (Reasoning, Self-Attn).
* **æ·±åº¦ç›‘ç£ (Deep Supervision)**: åœ¨å¤šä¸ªæ¨ç†å±‚çº§æŒ‚è½½åˆ†ç±»å¤´ï¼Œæå‡ä¸­é—´å±‚ç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›.
* **å¼ºåŒ–å­¦ä¹ å¾®è°ƒ (RL Fine-tuning)**: é›†æˆ PPO Agentï¼Œæ”¯æŒè”åˆä¼˜åŒ–åˆ†ç±»å¤´ä¸ç­–ç•¥ç½‘ç»œï¼Œå…·å¤‡åŠ¨æ€ä¿®æ­£ Query çš„èƒ½åŠ›.
* **InternViT ä¸»å¹²**: åˆ©ç”¨ InternViT-300M å¼ºå¤§çš„è§†è§‰ç‰¹å¾æå–èƒ½åŠ›ï¼Œæ”¯æŒ Pixel Unshuffle å’Œ MLP æŠ•å½±.

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„ (Technical Architecture)

### æ ¸å¿ƒç»„ä»¶
* **Vision Encoder**: åŸºäº `InternViT-300M-448px-V2_5`ï¼Œæ”¯æŒå†»ç»“å‚æ•°ä¸å±‚é€‰æ‹©.
* **Fusion Transformer**: åŒ…å« `FusionTransformerBlock2`ï¼Œæ”¯æŒ FlashAttention åŠ é€Ÿã€‚
* **RL Agent**: åŸºäº PPO (Proximal Policy Optimization) çš„ Actor-Critic ç½‘ç»œï¼Œè¾“å‡ºè¿ç»­åŠ¨ä½œ (Correction) å’Œ ç¦»æ•£åŠ¨ä½œ (Stop).

### æ¨¡å‹æµå‘å›¾
```mermaid
graph TD
    subgraph Input
        IMG1[Image T1]
        IMG2[Image T2]
    end

    subgraph "Vision Backbone (InternViT)"
        VE[Vision Encoder]
    end

    subgraph "Assembled Fusion Model"
        QG[Query Generator]
        PE[Positional Embedder]
        
        subgraph "Transformer Layers (Alternating)"
            SL[Sensing Layer (Even)]
            RL[Reasoning Layer (Odd)]
            SL -- Query Interaction --> RL
            VE -- Visual Feat --> SL
        end
        
        Heads[Multitask Classifiers]
        RL -.-> |Deep Supervision| Heads
    end

    IMG1 & IMG2 --> VE
    VE --> SL
    QG --> SL
    Heads --> Output[Change Predictions]

```

---

## ğŸ“‚ é¡¹ç›®ç»“æ„ (Project Structure)

```text
.
â”œâ”€â”€ configs/                # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ defaults.yaml       # å…¨å±€é»˜è®¤é…ç½® (æ•°æ®è·¯å¾„, æ¨¡å‹å‚æ•°, Lossæƒé‡)
â”‚   â”œâ”€â”€ rl_stage.yaml       # RL é˜¶æ®µç‰¹å®šé…ç½®
â”‚   â””â”€â”€ warmup_stage.yaml   # é¢„çƒ­è®­ç»ƒé…ç½®
â”œâ”€â”€ dataset/                # æ•°æ®åŠ è½½æ¨¡å—
â”‚   â”œâ”€â”€ dataset.py          # SVIPairsDataset å®šä¹‰ï¼Œå¤„ç†å›¾åƒåˆ‡ç‰‡ä¸CSVè¯»å–
â”‚   â”œâ”€â”€ dataloader.py       # Dataloader æ„å»ºé€»è¾‘
â”‚   â””â”€â”€ transforms.py       # å›¾åƒå¢å¼ºä¸é¢„å¤„ç†
â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ model.py            # ä¸»æ¨¡å‹ AssembledFusionModel
â”‚   â”œâ”€â”€ vision/             # è§†è§‰ä¸»å¹² (backbone.py)
â”‚   â”œâ”€â”€ transformer/        # Transformer å—ä¸ Attention å®ç°
â”‚   â”œâ”€â”€ heads/              # å¤šä»»åŠ¡åˆ†ç±»å¤´
â”‚   â””â”€â”€ position_embedding_v2.py # ä½ç½®ç¼–ç 
â”œâ”€â”€ rl/                     # å¼ºåŒ–å­¦ä¹ æ¨¡å—
â”‚   â”œâ”€â”€ agent.py            # PPOAgent (Actor-Critic, Update Logic)
â”‚   â”œâ”€â”€ env.py              # RL ç¯å¢ƒå°è£…
â”‚   â”œâ”€â”€ buffer.py           # Rollout Buffer
â”‚   â”œâ”€â”€ networks.py         # ActorCriticNetwork å®šä¹‰
â”‚   â””â”€â”€ rewards.py          # å¥–åŠ±å‡½æ•°è®¡ç®—
â”œâ”€â”€ scripts/                # è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ DL train.py         # æ·±åº¦å­¦ä¹ (ç›‘ç£)è®­ç»ƒå…¥å£
â”‚   â”œâ”€â”€ RL train.py         # å¼ºåŒ–å­¦ä¹ è®­ç»ƒå…¥å£
â”‚   â””â”€â”€ inference.py        # æ¨ç†è„šæœ¬
â”œâ”€â”€ trainer/                # è®­ç»ƒå™¨é€»è¾‘
â”‚   â”œâ”€â”€ base_trainer.py     # åŸºç¡€ç›‘ç£å­¦ä¹ è®­ç»ƒå™¨
â”‚   â””â”€â”€ rl_trainer.py       # PPO è®­ç»ƒå™¨
â””â”€â”€ utils/                  # å·¥å…·åº“ (Logger, Config, Loss)

```

---

## âš™ï¸ å®‰è£…ä¸ä¾èµ– (Installation)

æœ¬é¡¹ç›®ä¾èµ– Python 3.10+ å’Œ PyTorch 2.0+ã€‚

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n change_det python=3.10
conda activate change_det

# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬é€‰æ‹©)
pip install torch torchvision --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)

```

### 2. å®‰è£…ä¾èµ–

è¯·ç¡®ä¿å®‰è£…ä»¥ä¸‹æ ¸å¿ƒåº“ï¼š

```bash
pip install transformers numpy pandas pyyaml pillow scikit-learn
# å¦‚æœä½¿ç”¨ FlashAttention
pip install flash-attn --no-build-isolation

```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quick Start)

### 1. æ•°æ®å‡†å¤‡

è¯·åœ¨ `configs/defaults.yaml` ä¸­é…ç½®æ•°æ®è·¯å¾„ã€‚æ•°æ®åº”åŒ…å«ï¼š

* **å›¾åƒæ–‡ä»¶å¤¹**: å­˜æ”¾ T1 å’Œ T2 æ—¶åˆ»çš„å›¾ç‰‡ã€‚
* **CSV æ–‡ä»¶**: åŒ…å«æ–‡ä»¶åç´¢å¼• (`OID_`, `name_15`, `name_19`) å’Œ æ ‡ç­¾åˆ— (`A01_01_label` ç­‰).

**CSV æ ¼å¼ç¤ºä¾‹:**
| OID_ | name_15 | name_19 | A01_01_label | ... |
|------|---------|---------|--------------|-----|
| 1001 | img_a   | img_b   | 1            | ... |

### 2. ç›‘ç£è®­ç»ƒ (Warmup / DL Stage)

ä½¿ç”¨ `DL train.py` è¿›è¡ŒåŸºç¡€æ¨¡å‹çš„ç›‘ç£è®­ç»ƒã€‚

```bash
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
export PYTHONPATH=$PYTHONPATH:.

# è¿è¡Œè®­ç»ƒ
python scripts/DL\ train.py

```

*é…ç½®è°ƒæ•´*: ä¿®æ”¹ `configs/defaults.yaml` ä¸­çš„ `train` éƒ¨åˆ†å‚æ•° (å¦‚ `lr`, `batch_size`).

### 3. å¼ºåŒ–å­¦ä¹ å¾®è°ƒ (RL Stage)

åœ¨ç›‘ç£è®­ç»ƒå®Œæˆåï¼ŒåŠ è½½é¢„è®­ç»ƒæƒé‡è¿›è¡Œ RL å¾®è°ƒã€‚

```bash
# è¿è¡Œ RL è®­ç»ƒ
python scripts/RL\ train.py

```

*æ³¨æ„*: éœ€åœ¨ `configs/defaults.yaml` çš„ `rl` éƒ¨åˆ†æŒ‡å®š `pre_model_path` ä¸ºé¢„è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ (e.g., `./results/checkpoints/model_best.pth`).

---

## ğŸ“Š æ¨¡å‹è¾“å…¥ä¸è¾“å‡º

* **Input**:
* `pixel_values_t1`: [Batch, N_patches, 3, 448, 448] (ç»è¿‡ InternViT processor å¤„ç†)
* `pixel_values_t2`: [Batch, N_patches, 3, 448, 448]


* **Output**:
* `all_results`: å­—å…¸ï¼ŒåŒ…å«ä¸åŒ Reasoning å±‚çš„åˆ†ç±»ç»“æœã€‚
* Key: `ClassifyLayer_{i}`
* Value: Logits [Batch, Num_Tasks, 2].



## ğŸ“œ è®¸å¯è¯ (License)

MIT License

---

*Created by Project Team*

```


```
