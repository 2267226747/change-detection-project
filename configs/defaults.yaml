# project/configs/defaults.yaml

# -------------------------
# 1. 数据相关 (Data)
# -------------------------
data:
  image_patches_size: 448      #将图片分割成大子块的大小
  patch_size: 14               #子块再次分割的大小
  batch_size: 4
  patches_h_num: 3             #大子块的行数
  patches_w_num: 9             #打字快的列数
  patches_min_num: 1           #最小子块数量
  patches_max_num: 128         #最大子块数量
  patches_num: 28              #所有子块的数量，包括缩略图   patches_h_num * patches_w_num + 1
  use_thumbnail: True
  vision_dim: 1024             # vision token经过unshuffle后的维度
  num_workers: 16

  # 数据根目录 (根据你的实际路径修改)
  train_image_dir: "/root/autodl-tmp/data/SVI image(panorama)_Wuhan"
  train_csv_path: "./model/project/Data/test_train_data.csv"
  val_image_dir: "/root/autodl-tmp/data/SVI image(panorama)_Wuhan"
  val_csv_path: "./model/project/Data/test_val_data.csv"
  # CSV 中的关键列名
  col_oid: "OID_"
  col_name_t1: "name_15"
  col_name_t2: "name_19"
  # 所有需要预测的任务标签列名 (按顺序)
  label_columns: [
    "A01_01_label", "A01_02_label", "A01_03_label", "A01_04_label",
    "A02_01_label", "A02_02_label", "A03_01_label", "A03_02_label",

    "B01_01_label", "B01_02_label", "B01_03_label", "B01_04_label",
    "B02_01_label", "B02_02_label", "B03_01_label", "B03_02_label",

    "C01_01_label", "C01_02_label", "C02_01_label", "C02_02_label",
    "C02_03_label", "C03_01_label", "C03_02_label",

    "D01_01_label", "D01_02_label", "D02_01_label", "D02_02_label",
    "D03_01_label", "D03_02_label", "D04_01_label", "D04_02_label"
  ]

# -------------------------
# 2. 模型结构 (Model)
# -------------------------
model:

  # Assembled Model
  assembled_model:
    num_layers: 18                # T_t 堆叠层数
    start_classify: 1              # 开始挂载分类头的位置     start_classfy*2，因为只在reasoning层进行分类

  # 视觉编码器 (Vision Encoder)
  vision:
    backbone: "/root/autodl-tmp/package/InternViT/InternViT-300M-448px-V2_5"
    num_tokens: 7168             # vision token的总数量
    feature_dim: 1024            # InternViT vision token 原始输出维度
    freeze_backbone: Ture        # 是否冻结视觉部分参数
    select_layer: -1           # [新增] 选择倒数第几层的输出 (官方建议 -4)
    vision_dim: 1024             # vision token经过unshuffle后的维度

  # query token
  query_token:
    total_tokens: 512
    task_nums: 4
    tokens_per_task: 128
    query_dim: 1024
    batch_size: 4

  # 时序 Transformer (Temporal Transformer)
  transformer_block:
    query_dim: 1024                  # Query token的维度 (也是block的主干维度)
    vision_dim: 1024                 # vision token经过unshuffle后的维度
    num_head: 16                     # 多头注意力头数
    mlp_ratio: 4.0                   # FNN hidden_dim = mlp_ratio*query_dim
    dropout: 0.1
    use_qk_norm: True
    if_q_position: False
    if_k_position: True
    if_v_position: False
    norm_layer: "RMSNorm"
    act_layer: "GELU"
    fusion_type: "cross_attn"

  # 任务头 (Heads)
  # [4096] -> (融合) -> [1024] -> (聚合) -> [2048] -> (Head降维) -> [256] -> [2]
  class_head:
    task_dicts: [{road: 8},
                 {building: 8},
                 {greenery: 7},
                 {infrastructure: 8}]        # 大类及任务数量
    query_dim: 1024                          # Query token的维度 (也是 block 的输出维度)
    hidden_dim: 1024                         # query 聚合后降维的维度
    mid_hidden_dim: 256                      # 子分类头中间层（hidden_dim*2 -> mid_hidden_dim -> 2）
    drop_out: 0.1


# -------------------------
# 3. Loss损失函数权重
# -------------------------
loss:
  # 选择 loss 类型
  type: 'Focal'       # 或 'Focal'
  layer_weights: [0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.6, 0.8, 1.0]   # Deep Supervision 层级权重 (9个 Reasoning 层)

  # --- 任务定义与权重配置 ---
  # 这里的顺序必须与 Dataset 中 label 拼接的顺序一致！
  # 假设 dataset 输出的 labels tensor 是拼接了 [road, building, greenery, infrastructure] 的
  tasks:
    road:
      num_classes: 8
      # 针对 BCE 的 pos_weight (长度必须等于 8)
      pos_weight: [1.5, 10.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0]
      # 针对 Focal 的 alpha (长度必须等于 8)，列表中的每一个值，都代表该属性 Label 为 1 （有变化）时的权重
      focal_alpha: [0.7401, 0.8899, 0.6564, 0.8502, 0.6828, 0.815, 0.7137, 0.9075]
      focal_gamma: [2.48, 2.78, 2.313, 2.7, 2.366, 2.63, 2.427, 2.815]

    building:
      num_classes: 8
      pos_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] # 假设比较平衡
      focal_alpha: [0.6608, 0.8458, 0.7445, 0.5374, 0.9, 0.9, 0.7357, 0.7269]
      focal_gamma: [2.322, 2.692, 2.489, 2.075, 2.965, 2.965, 2.471, 2.454]

    greenery:
      num_classes: 7
      pos_weight: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
      focal_alpha: [0.8943, 0.9207, 0.7665, 0.7533, 0.3656, 0.8943, 0.96]
      focal_gamma: [2.789, 2.841, 2.533, 2.507, 1.731, 2.789, 3.0]

    infrastructure:
      num_classes: 8
      pos_weight: [1.0, 10.0, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0]
      focal_alpha: [0.9, 0.8282, 0.7048, 0.9, 0.9163, 0.7313, 0.9, 0.9]
      focal_gamma: [2.885, 2.656, 2.41, 2.956, 2.833, 2.463, 2.921, 2.947]




# -------------------------
# 4. 训练超参 (Training)
# -------------------------
train:
  seed: 42
  lr: 0.0001                        # 学习率
  weight_decay: 0.0001
  epochs: 100
  device: "cuda"                  # "cuda" or "cpu"
  save_dir: "./model/project/results/"
  use_amp: True

# -------------------------
# 5. 强化学习 (RL - Step 2)
# -------------------------
rl:
  pre_model_path: "./model/project/results/checkpoints/model_best.pth"
  device: "cuda"
  freeze_classifier: "False"
  hidden_dim: 512 # Env 返回的 Dict Obs 编码为统一的 Hidden State 的 dim
